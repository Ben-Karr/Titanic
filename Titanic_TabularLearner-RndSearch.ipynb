{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install kaggle --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.tabular import *\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data')\n",
    "path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data # \n",
    "The preprocessing was done in the [Titanic_TabularLearner](Titanic_TabularLearner.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path /'titanic_preproc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split prepocessed dataframe from 'is_test' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['is_test'] == False].drop('is_test', axis = 1)\n",
    "df_test = df[df['is_test'] == True].drop(['is_test','Survived'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Survived'] = df_train['Survived'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataframe #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_var = 'Survived' # target variable\n",
    "cat_names = ['LName','Pclass','Sex','SibSp','Parch','Cabin','Title']\n",
    "cont_names = ['Age','Fare']\n",
    "procs = [FillMissing, Categorify, Normalize]\n",
    "t_procs = [partial(FillMissing,test=True), partial(Categorify,test=True),partial(Normalize,test=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = TabularList.from_df(df_test, path='.', cat_names=cat_names, cont_names=cont_names, procs = t_procs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (TabularList.from_df(df_train, path = path, cat_names=cat_names, cont_names=cont_names, procs = procs)\n",
    "        .split_by_rand_pct(0.2, seed = 41) # Force the DataBunch to learn on all data. Hyperparameters come from a random search.\n",
    "        .label_from_df(cols = dep_var)\n",
    "        .add_test(test)\n",
    "        .databunch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a random search to find 'the best' hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = []\n",
    "y_range = [0, 1.2]\n",
    "\n",
    "while(True):\n",
    "    wd = random.randrange(5,100)/1000\n",
    "    emb_drop = random.randrange(5,100)/1000\n",
    "    \n",
    "    exp = random.choice([0,1,2,3,4])\n",
    "    lr = random.random() / (10**exp)\n",
    "\n",
    "    layers = random.choice([[100,50],[200,100],[100,200,50],[1000,500],[2000,1000]])\n",
    "    ps = random.randrange(0,7)/10\n",
    "    mom = 0.1\n",
    "    opt_func = random.choice([optim.SGD,optim.Adam])\n",
    "\n",
    "\n",
    "    \n",
    "    learn = tabular_learner(data, layers = layers, metrics = (accuracy,error_rate),\n",
    "                        ps = ps, emb_drop = emb_drop, y_range = y_range, \n",
    "                        opt_func = opt_func)\n",
    "    \n",
    "    print('Learning on: layout {}, lr {}, dropout {}, emb_drop {}, wd {} with {}.'.format(layers,lr,ps,emb_drop,wd,opt_func))\n",
    "    learn.fit_one_cycle(40, lr, wd)\n",
    "    \n",
    "    \n",
    "    t_loss = learn.recorder.losses[-1]\n",
    "    v_loss = learn.recorder.val_losses[-1]\n",
    "    acc, err = learn.recorder.metrics\n",
    "    \n",
    "    setup = [wd, emb_drop, layers, ps, opt_func, lr]\n",
    "    result = [t_loss,v_loss,acc,err]\n",
    "    \n",
    "    record.append((setup,result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build DataFrame from hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = [x[0][0] for x in record]\n",
    "emb_drop = [x[0][1] for x in record]\n",
    "layers = [str(x[0][2]) for x in record]\n",
    "dropout = [x[0][3] for x in record]\n",
    "opt_func = [str(x[0][4]) for x in record]\n",
    "t_loss = [x[1][0].item() for x in record]\n",
    "v_loss = [x[1][1] for x in record]\n",
    "acc = [x[1][2].item() for x in record]\n",
    "err = [x[1][3].item() for x in record]\n",
    "lr = [x[0][5] for x in record]\n",
    "\n",
    "dic = {'accuracy': acc,\n",
    "       'error': err,\n",
    "       'learning rate': lr,\n",
    "       'wd': wd,\n",
    "       'emb_drop': emb_drop,\n",
    "       'layers': layers,\n",
    "       'dropout': dropout,\n",
    "       'opt_func': opt_func,\n",
    "       't_loss': t_loss,\n",
    "       'v_loss': v_loss\n",
    "      }\n",
    "\n",
    "hyper_df = pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort for best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_df.sort_values(['accuracy'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|accuracy | error| \tlearning rate |\twd |\temb_drop |\tlayers |\tdropout |\topt_func | t_loss |\tv_loss |\n",
    "|----------|:-----------:|:-----------:|:-----------:|:-----------:|:-----------:|:-----------:|:-----------:|:-----------:|----------:|\n",
    "| \t0.882023 |\t0.117978  |\t0.097620 |\t0.014 |\t0.055 |\t[100, 200, 50] |\t0.3 |\t<class 'torch.optim.adam.Adam'> |\t0.292863 |\t0.406563 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
